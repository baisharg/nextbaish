{
  "header": {
    "nav": {
      "about": "Sobre nosotros",
      "activities": "Programas",
      "research": "Investigación",
      "resources": "Recursos",
      "contact": "Contacto"
    },
    "cta": "Sumate",
    "language": "Idioma",
    "languages": {
      "en": "English",
      "es": "Español"
    },
    "menu": "Menu",
    "closeMenu": "Cerrar menu",
    "openMenu": "Abrir menu"
  },
  "footer": {
    "copyright": "Todos los derechos reservados.",
    "nav": {
      "about": "Sobre nosotros",
      "activities": "Programas",
      "research": "Investigación",
      "resources": "Recursos",
      "contact": "Contacto",
      "getInvolved": "Participá",
      "privacyPolicy": "Política de privacidad"
    }
  },
  "substack": {
    "eyebrow": "Boletin",
    "title": "Sumate a nuestra lista de correo",
    "description": "Mantenete al tanto de nuestras actividades, eventos y oportunidades.",
    "placeholder": "tu@email.com",
    "button": "Suscribite",
    "disclaimer": "Solo enviaremos correos cuando haya novedades importantes.",
    "success": "¡Te suscribiste! Revisá tu correo para el mensaje de bienvenida.",
    "confirm": "Queda un paso — confirmá la suscripción desde tu bandeja de entrada.",
    "genericError": "Ocurrió un error. Intentá nuevamente.",
    "networkError": "Fallo de conexión. Verificá tu internet e intentalo otra vez."
  },
  "home": {
    "breadcrumb": {
      "home": "Inicio"
    },
    "mission": {
      "eyebrow": "Mision",
      "title": "Asegurando que la IA Beneficie a la Humanidad",
      "paragraph1": "A medida que los modelos de inteligencia artificial avanzan en capacidades{footnote1}, esperamos que tengan un impacto cada vez más profundo en nuestra sociedad{footnote2}. Es esencial que este impacto sea positivo, y que las decisiones tomadas por estos sistemas sean transparentes, confiables y responsables{footnote3} ante las personas afectadas por ellos.",
      "paragraph2": "Creemos que reducir los riesgos asociados a modelos avanzados de IA{footnote4} es uno de los desafíos más importantes de nuestro tiempo. También creemos que es un problema abierto y apasionante{footnote5}, con amplias oportunidades para que más investigadores avancen en este campo{footnote6}.",
      "paragraph3": "La misión de BAISH es apoyar a estudiantes a entrar a este campo y a realizar investigaciones sobre este tema.",
      "cta": "Participá"
    },
    "events": {
      "eyebrow": "Proximos Eventos",
      "title": "Sumate a nuestros talleres y encuentros comunitarios",
      "description": "Mantenete al día con discusiones sobre seguridad en IA, sprints de investigación y espacios colaborativos.",
      "calendarPlaceholder": "El calendario se carga al acercarse a la vista para mantener la carga inicial rápida.",
      "subscribe": "Suscribite al calendario"
    },
    "activities": {
      "title": "Nuestros Programas",
      "description": "Explora los programas recurrentes diseñados para crecer la comunidad de seguridad en IA.",
      "items": {
        "fundamentals": {
          "eyebrow": "Curso",
          "title": "AI Safety Fundamentals",
          "description": "Curso de aula invertida con discusiones semanales sobre alineamiento de IA y mini-proyecto final.",
          "schedule": "Viernes · 14:30",
          "duration": "13 semanas"
        },
        "workshop": {
          "eyebrow": "Taller",
          "title": "AIS Research Workshop",
          "description": "Taller técnico para replicar investigaciones recientes de AI Safety mediante programación.",
          "schedule": "Martes · 14:30",
          "duration": "2.5 hrs"
        },
        "reading": {
          "eyebrow": "Actividades",
          "title": "Club del Paper",
          "description": "Presentaciones completas de papers por miembros de la comunidad con grabaciones en YouTube.",
          "schedule": "Jueves alternos · 15h",
          "duration": "2 hrs"
        }
      },
      "joinNow": "Inscribite",
      "joinTelegram": "Sumate al Telegram",
      "learnMore": "Ver más"
    },
    "aisar": {
      "eyebrow": "Proyecto Hermano",
      "title": "Becas AISAR",
      "description": "Programa presencial part-time para estudiantes avanzados que trabajan en proyectos de investigación en AI Safety. Estipendio de $600/mes + presupuesto para cómputo. Temas incluyen interpretabilidad, evaluaciones y supervisión.",
      "duration": "6 meses",
      "commitment": "20 hrs/semana",
      "visitWebsite": "Visitar sitio web"
    },
    "resources": {
      "title": "Recursos",
      "description": "Profundiza en la seguridad de IA con lecturas y herramientas seleccionadas.",
      "items": {
        "reading": {
          "eyebrow": "Recursos",
          "title": "Lecturas Iniciales",
          "description": "Ensayos y papers fundamentales para orientarte en investigación de alineamiento.",
          "meta": "15+ papers"
        },
        "toolkit": {
          "eyebrow": "Recursos",
          "title": "Kit de Herramientas",
          "description": "Repositorios de código, benchmarks y plantillas de experimentos para investigación.",
          "meta": "Herramientas"
        },
        "handbook": {
          "eyebrow": "Recursos",
          "title": "Manual Comunitario",
          "description": "Guía para organizar encuentros y facilitar discusiones productivas.",
          "meta": "Guia"
        }
      },
      "viewResource": "Ver recurso",
      "learnMore": "Ver más"
    },
    "getInvolved": {
      "communityEyebrow": "Comunidad",
      "communityTitle": "Sumate a nuestra comunidad",
      "communityDescription": "Conéctate con estudiantes interesados en la seguridad de IA.",
      "telegramCta": "AI Safety Argentina",
      "telegramMembers": "190+ miembros",
      "whatsappCta": "Comunidad BAISH",
      "whatsappMembers": "140+ miembros"
    }
  },
  "about": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Seguridad en IA"
    },
    "title": "Entendiendo la Seguridad en IA",
    "coreConcepts": {
      "whatIsAiSafety": {
        "title": "¿Que es la Seguridad en IA?",
        "content": "La Seguridad en IA es un campo de investigación enfocado en asegurar que los sistemas avanzados de inteligencia artificial sigan siendo beneficiosos, alineados con los valores humanos y bajo control humano a medida que se vuelven más capaces. Abarca áreas técnicas de investigación como alineamiento, interpretabilidad y robustez, así como consideraciones de gobernanza sobre cómo deberían desarrollarse e implementarse los sistemas de IA."
      },
      "whyItMatters": {
        "title": "¿Por que es Importante?",
        "content": "A medida que los sistemas de IA se vuelven más poderosos y autónomos, pueden desarrollar capacidades que podrían llevar a consecuencias no deseadas si no están diseñados y controlados adecuadamente. Lo que está en juego es importante: la IA avanzada podría ayudar a resolver los mayores desafíos de la humanidad, pero también presenta riesgos significativos si se desarrolla sin medidas de seguridad adecuadas. El campo busca maximizar los beneficios mientras minimiza los daños potenciales."
      },
      "risks": {
        "title": "Riesgos y Desafios Principales",
        "alignment": {
          "title": "Problema de Alineamiento",
          "description": "Asegurar que los sistemas de IA persigan objetivos alineados con los valores e intenciones humanas, incluso cuando se vuelven más capaces."
        },
        "interpretability": {
          "title": "Interpretabilidad",
          "description": "Desarrollar técnicas para entender cómo los sistemas de IA toman decisiones y representan conocimiento."
        },
        "robustness": {
          "title": "Robustez",
          "description": "Crear sistemas que se comporten de manera segura incluso cuando se implementan en nuevos entornos o enfrentan situaciones inesperadas."
        },
        "powerSeeking": {
          "title": "Comportamiento de Busqueda de Poder",
          "description": "Prevenir que los sistemas de IA desarrollen objetivos instrumentales que entren en conflicto con el bienestar humano."
        },
        "coordination": {
          "title": "Desafios de Coordinacion",
          "description": "Garantizar que se mantengan estándares de seguridad en todos los principales esfuerzos de desarrollo de IA a nivel mundial."
        }
      }
    },
    "ourApproach": {
      "title": "Nuestro Enfoque",
      "focusAreas": {
        "title": "Areas de Enfoque",
        "intro": "En BAISH - Buenos Aires AI Safety Hub, nos enfocamos en varias áreas clave dentro de la investigación de seguridad en IA:",
        "items": [
          "Interpretabilidad de Cadena de Pensamiento",
          "Evaluaciones de LLMs",
          "Interpretabilidad mecanica de redes neuronales"
        ]
      },
      "contribution": {
        "title": "Nuestra Contribucion",
        "intro": "Contribuimos al campo a través de:",
        "items": [
          "Apoyando proyectos de investigación estudiantil",
          "Construyendo una comunidad regional de investigadores en seguridad de IA",
          "Organizando talleres, programas de formación y hackathons",
          "Mentoreando a estudiantes interesados en carreras de seguridad en IA"
        ]
      }
    },
    "team": {
      "title": "Equipo Principal",
      "meetTheTeam": "Conoce al Equipo",
      "cofoundersTitle": "Fundadores",
      "leadershiptTitle": "Liderazgo",
      "roles": {
        "coDirector": "Co-director Fundador",
        "commDirector": "Director de Comunicación",
        "headOfStrategy": "Director de Estrategia",
        "advisor": "Advisor"
      },
      "volunteersTitle": "Voluntarios",
      "volunteerRoles": {
        "asfFacilitator": "Facilitador de AI Safety Fundamentals",
        "aisWorkshopFacilitator": "Facilitador del AIS Workshop",
        "programAssistant": "Asistente de Programas"
      },
      "bios": {
        "eitan": "Eitan es co-director fundador de BAISH con experiencia en investigación de seguridad en IA e interpretabilidad. Lidera iniciativas de investigación técnica y ayuda a coordinar las actividades de investigación de la comunidad.",
        "luca": "Luca es co-director fundador de BAISH enfocado en construir la comunidad de investigación de seguridad en IA en Buenos Aires. Aporta experiencia en aprendizaje automático y le apasiona hacer la investigación en seguridad de IA más accesible."
      }
    },
    "support": {
      "title": "Apoyo Externo",
      "description": "BAISH cuenta con el apoyo de:",
      "openPhilanthropy": {
        "name": "Open Philanthropy",
        "description": "La misión de Open Philanthropy es donar de la manera más efectiva posible para ayudar a otros tanto como sea posible."
      },
      "kairos": {
        "name": "Kairos",
        "program": "Programa Pathfinder",
        "description": "Kairos apoya el desarrollo del campo de seguridad en IA a través de su programa Pathfinder, que ayuda a acelerar iniciativas prometedoras."
      }
    }
  },
  "activities": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Programas"
    },
    "title": "Nuestros Programas",
    "description": "Sumate a nuestra comunidad y participá en investigación y aprendizaje de seguridad en IA",
    "subscribeCalendar": "Suscribite al calendario de eventos",
    "agiSafety": {
      "title": "AI Safety Fundamentals",
      "status": "Actualmente activo",
      "description": "La actividad consiste en discutir y dar seguimiento de forma presencial a los contenidos del curso de BlueDot: AI Alignment, los cuales deben ser completados de forma asíncrona.",
      "overview": "El curso (extra-oficial) tiene la modalidad de aula invertida. Cada semana, los participantes tendrán que venir con el contenido leído/visto (2-3hs), y los Viernes de 14:30 a 17:00 nos encontraremos presencialmente.",
      "whatToExpect": "Modalidad del Curso",
      "expectations": [
        "13 encuentros en total: 9 conceptuales + 4 de proyecto",
        "Encuentros conceptuales: Discusiones sobre contenidos con dinámicas pre-armadas",
        "Encuentros de proyecto: Mini-proyecto personal con mentoría",
        "2-3 horas semanales de contenido asíncrono",
        "2.5 horas semanales presenciales (Viernes 14:30-17:00)",
        "Certificado de compleción (requiere 7/9 encuentros + proyecto final)"
      ],
      "whoWeSeek": "¿A quienes buscamos?",
      "seekCriteria": [
        "Te interesa abordar conceptos como vulnerabilidades en sistemas de IA o riesgos existenciales",
        "Querés explorar qué oportunidades hay en el campo y tus siguientes pasos a seguir",
        "Estás dispuesto a participar en discusiones abiertas",
        "Tenés buen nivel de inglés",
        "Podes dedicarte a hacer el curso presencialmente (2.5 horas semanales aproximadamente)",
        "Podes dedicarte a realizar las actividades asincrónicas y revisar el material (3 horas semanales aproximadamente)"
      ],
      "programDetails": "Detalles del Programa",
      "duration": "13 semanas",
      "fellowshipPeriod": "Viernes 14:30-17:00",
      "viewCurriculum": "Ver curriculo",
      "applyNow": "Aplicá ahora"
    },
    "aisWorkshop": {
      "title": "AIS Research Workshop",
      "schedule": "Todos los martes @ 14:30",
      "description": "La actividad consiste en discutir y replicar (programando) investigaciones recientes sobre AI Safety de forma presencial para adquirir las habilidades técnicas necesarias para poder investigar de forma independiente.",
      "overview": "Este taller se llevará a cabo los martes de 14:30 a 17:00 y está diseñado para estudiantes que quieren desarrollar habilidades técnicas prácticas en seguridad de IA.",
      "whoWeSeek": "¿A quienes buscamos?",
      "seekCriteria": [
        "Podes dedicarte al menos 5 horas semanales (2 hrs presenciales + 3 hrs asincrónicas)",
        "Tenés buen nivel de inglés",
        "Estás dispuesto a participar en discusiones abiertas",
        "Te interesa adquirir habilidades técnicas sobre ML y Safety",
        "Querés adentrarte en el campo y dar los primeros pasos como investigador"
      ],
      "formatTitle": "Formato del Taller",
      "format": [
        "Sesiones presenciales de 2.5 horas los martes",
        "Discusión de papers recientes de AI Safety",
        "Implementación práctica programando los métodos discutidos",
        "Trabajo asincrónico para familiarizarse con el material (3 hrs/semana)",
        "Mentoría para desarrollar habilidades de investigación independiente"
      ],
      "nextSession": "Proxima Sesion",
      "date": "Consultar calendario",
      "time": "14:30 - 17:00",
      "location": "Pabellon 0+inf, Ciudad Universitaria",
      "topic": "A definir semanalmente",
      "joinTelegram": "Sumate a Telegram para actualizaciones",
      "joinWhatsapp": "Sumate al WhatsApp",
      "applyNow": "Aplicá ahora"
    },
    "paperReading": {
      "title": "Club del Paper",
      "schedule": "Jueves alternos @ 15:00",
      "description": "El Club del Paper presenta papers completos de seguridad en IA e IA en general expuestos por miembros de la comunidad. Cada sesión incluye una presentación profunda seguida de discusión.",
      "overview": "Las presentaciones son grabadas y subidas a nuestro canal de YouTube para que la comunidad pueda revisarlas posteriormente.",
      "selectionCriteriaTitle": "¿Que Esperamos?",
      "criteria": [
        "Presentaciones completas de papers por miembros de la comunidad",
        "Análisis profundo de métodos y resultados",
        "Discusión abierta sobre implicaciones",
        "Grabaciones disponibles en YouTube"
      ],
      "sessionFormatTitle": "Formato de Sesion",
      "format": [
        "Presentación completa del paper (30-40 minutos)",
        "Discusión abierta y preguntas (30-40 minutos)",
        "Sesión grabada y subida a YouTube",
        "Chat de Telegram para coordinación y discusión continua"
      ],
      "nextSession": "Proxima Sesion de Paper",
      "paper": "Consultar en Telegram o calendario",
      "discussionLead": "Miembro de la comunidad",
      "accessList": "Ver grabaciones en YouTube",
      "date": "Consultar calendario",
      "time": "15:00 - 17:00",
      "location": "Pabellon 0+inf, Ciudad Universitaria",
      "youtubeChannel": "Canal de YouTube",
      "telegramGroup": "Grupo de Telegram"
    },
    "common": {
      "duration": "Duracion:",
      "startDate": "Fecha de inicio:",
      "endDate": "Fecha de finalizacion:",
      "applicationDeadline": "Fecha limite de inscripcion:",
      "location": "Ubicacion:",
      "instructors": "Instructores:",
      "fellowshipPeriod": "Periodo de Fellowship:",
      "date": "Fecha:",
      "time": "Hora:",
      "topic": "Tema:",
      "facilitator": "Facilitador:",
      "paper": "Paper:",
      "discussionLead": "Lider de Discusion:"
    },
    "gallery": {
      "eyebrow": "Comunidad",
      "title": "Eventos Pasados",
      "description": "Momentos de nuestros encuentros y actividades recientes"
    }
  },
  "contact": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Contacto"
    },
    "title": "Contactanos",
    "description": "Comunicate con la comunidad de BAISH",
    "linkText": {
      "resourcesPage": "página de Recursos"
    },
    "cards": {
      "telegram": {
        "title": "Telegram",
        "description": "Sumate a nuestro canal de comunidad para discusiones y actualizaciones:"
      },
      "location": {
        "eyebrow": "Visitanos",
        "title": "Ubicacion",
        "description": "Estamos ubicados en el Departamento de Ciencias de la Computación:"
      },
      "social": {
        "eyebrow": "Social",
        "title": "Redes Sociales",
        "description": "Seguinos para actualizaciones y anuncios:"
      }
    },
    "form": {
      "eyebrow": "Contacto",
      "title": "Contactanos",
      "description": "Comunicate con la comunidad de BAISH",
      "nameLabel": "¿Cuál es tu nombre?",
      "emailLabel": "¿Cuál es tu correo electrónico?",
      "messageLabel": "Mensaje",
      "clearForm": "Limpiar formulario",
      "submit": "Enviá"
    },
    "getInvolved": {
      "title": "Sumate",
      "description": "Hay múltiples formas de participar en nuestra comunidad y actividades.",
      "newsletter": {
        "title": "Suscribite a nuestra lista de correo",
        "description": "Mantenete al día con nuestros eventos, actividades y oportunidades suscribiéndote a nuestra lista de correo. Te enviamos newsletters mensuales y anuncios importantes."
      }
    },
    "faq": {
      "title": "Preguntas Frecuentes",
      "items": [
        {
          "question": "¿Necesito ser estudiante de la UBA para participar?",
          "answer": "¡No! Si bien estamos basados en la UBA, nuestras actividades están abiertas a todos los interesados en la seguridad de la IA, independientemente de su afiliación universitaria."
        },
        {
          "question": "¿Qué formación necesito para unirme a sus actividades?",
          "answer": "Depende de la actividad. Algunas, como nuestros grupos de discusión, están abiertas a cualquier persona independientemente de su formación técnica. Otras, como nuestros cursos técnicos, pueden requerir conocimientos de programación o familiaridad con conceptos de aprendizaje automático."
        },
        {
          "question": "¿Sus actividades se realizan en inglés o español?",
          "answer": "La mayoría de nuestras actividades se realizan en español, pero ocasionalmente tenemos sesiones en inglés, especialmente cuando recibimos oradores internacionales. Verifica los detalles del evento específico para obtener información sobre el idioma."
        },
        {
          "question": "¿Cómo puedo empezar a aprender sobre seguridad de IA si soy completamente nuevo en el campo?",
          "answer": "Recomendamos comenzar con nuestra {resourcesLink}, que tiene materiales seleccionados organizados por nivel de dificultad. También puedes unirte a nuestro grupo de discusión semanal para aprender junto con otros miembros de la comunidad."
        },
        {
          "question": "¿Puedo proponer una nueva actividad o dirección de investigación?",
          "answer": "¡Por supuesto! Siempre estamos abiertos a nuevas ideas y colaboraciones. Por favor completa el formulario de contacto arriba con tu propuesta."
        }
      ]
    }
  },
  "research": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Investigación"
    },
    "title": "Nuestra Investigación",
    "filterBy": "Filtrar por:",
    "filters": {
      "all": "Todos",
      "interpretability": "Interpretabilidad",
      "alignment": "Alineamiento",
      "robustness": "Robustez",
      "valueLearning": "Aprendizaje de Valores"
    },
    "approachTitle": "Enfoque de Investigacion",
    "focusAreasTitle": "Areas de Enfoque",
    "focusAreas": {
      "mechInterp": "Interpretabilidad Mecánica - Entender cómo las redes neuronales procesan información internamente",
      "alignment": "Alineamiento de IA - Asegurar que los sistemas de IA actúen de acuerdo a valores e intenciones humanas",
      "robustness": "Robustez y Pruebas Adversarias - Construir sistemas resilientes resistentes a ataques",
      "valueLearning": "Aprendizaje de Valores - Enseñar a los sistemas de IA a aprender y respetar preferencias humanas"
    },
    "projectsTitle": "Proyectos de Investigacion",
    "linkPlaceholder": "Enlace",
    "publicationsTitle": "Publicaciones",
    "ongoingTitle": "Investigacion en Curso",
    "started": "Iniciado",
    "expectedCompletion": "Finalizacion Esperada"
  },
  "resources": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Recursos"
    },
    "title": "Recursos de Aprendizaje",
    "description": "Materiales curados para explorar conceptos de seguridad en IA",
    "sections": {
      "featuredVideo": {
        "title": "Introduccion a la Seguridad en IA",
        "description": "Empieza aquí: Por qué los expertos temen la IA superinteligente – y qué podemos hacer al respecto"
      },
      "selfStudy": {
        "title": "Autoestudio",
        "lastUpdated": "Ultima actualizacion: 22 de octubre de 2025",
        "description": "Estos currículos y listas de lectura te permiten profundizar en la seguridad de IA a través del aprendizaje independiente.",
        "fundamentalReading": {
          "title": "Lecturas fundamentales",
          "items": [
            {
              "name": "AI Alignment Forum: Secuencias Curadas",
              "description": "Lista de secuencias curadas por el equipo del AI Alignment Forum, con trabajos de Richard Ngo, Paul Christiano, etc.",
              "category": "Alineacion Tecnica",
              "createdBy": "Varios",
              "url": "https://www.alignmentforum.org/library"
            }
          ]
        },
        "standardCourses": {
          "title": "Cursos introductorios estandar",
          "items": [
            {
              "name": "BlueDot Impact: Alineación y Gobernanza",
              "description": "Cubre conceptos clave y perspectivas de investigación en seguridad de IA, divididos en dos áreas principales: Alineación y Gobernanza. Anteriormente conocido como AI Safety Fundamentals.",
              "category": "Alineacion Tecnica, Gobernanza",
              "createdBy": "BlueDot Impact",
              "url": "https://bluedot.org/courses"
            }
          ]
        },
        "relatedResources": {
          "title": "Recursos relacionados",
          "eventsTraining": {
            "title": "Eventos y capacitacion",
            "description": "Próximas becas, conferencias, cursos facilitados, etc.",
            "url": "https://www.aisafety.com/events-and-training"
          },
          "aiDigest": {
            "title": "AI Digest",
            "description": "Explicaciones interactivas de capacidades y tendencias de IA",
            "url": "https://theaidigest.org/"
          }
        }
      },
      "externalOpportunities": {
        "title": "Oportunidades de Capacitacion Externa",
        "subtitle": "Proximos cursos, talleres y programas de organizaciones de todo el mundo",
        "description": "Hay una amplia gama de eventos y programas de capacitación en seguridad de IA, tanto online como presenciales. Estos te pueden ayudar a desarrollar habilidades, hacer conexiones y descubrir oportunidades.",
        "newsletter": {
          "title": "Suscribite al Newsletter de Nuevas Oportunidades",
          "description": "Recibí un email semanal resumiendo todos los nuevos eventos y programas de capacitacion",
          "cta": "Suscribite"
        }
      }
    }
  },
  "privacyPolicy": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Política de Privacidad"
    },
    "title": "Política de Privacidad",
    "sections": {
      "approach": {
        "title": "Nuestro Enfoque de Privacidad",
        "content": "En BAISH (Buenos Aires AI Safety Hub), estamos comprometidos a respetar tu privacidad. Esta Política de Privacidad describe nuestras prácticas con respecto a la recopilación, uso y protección de tu información cuando utilizas nuestro sitio web y servicios."
      },
      "dataCollection": {
        "title": "Recopilacion de Datos",
        "content": "Recopilamos información personal mínima. Los únicos datos personales que recopilamos son las direcciones de correo electrónico cuando los usuarios se registran voluntariamente para recibir nuestro boletín a través de Substack. Esta información es almacenada y gestionada por Substack de acuerdo con su política de privacidad."
      },
      "noTracking": {
        "title": "Sin Seguimiento ni Cookies",
        "content": "No utilizamos cookies, análisis, herramientas de seguimiento ni ninguna otra tecnología para recopilar datos sobre ti. No monitoreamos tus actividades de navegación ni recopilamos información sobre tus comportamientos en línea."
      },
      "thirdParty": {
        "title": "Servicios de Terceros",
        "content": "Nuestro boletín se gestiona a través de Substack. Cuando te suscribes a nuestro boletín, tu dirección de correo electrónico se comparte y almacena con Substack. Consulta la",
        "substackLink": "Política de Privacidad de Substack",
        "content2": "para comprender cómo manejan tu información."
      },
      "rights": {
        "title": "Tus Derechos",
        "content": "Tienes derecho a cancelar la suscripción a nuestro boletín en cualquier momento haciendo clic en el enlace para cancelar la suscripción en cualquiera de nuestros correos electrónicos o contactándonos directamente. Si tienes alguna pregunta sobre tus datos o deseas acceder, corregir o eliminar tu información, contáctanos."
      },
      "changes": {
        "title": "Cambios a Esta Politica",
        "content": "Podemos actualizar esta Política de Privacidad de vez en cuando. Te notificaremos cualquier cambio publicando la nueva Política de Privacidad en esta página."
      },
      "contact": {
        "title": "Contactanos",
        "content": "Si tienes alguna pregunta sobre esta Política de Privacidad, contáctanos a través de nuestra",
        "contactLink": "página de Contacto"
      }
    }
  }
}
