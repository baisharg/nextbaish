{
  "header": {
    "nav": {
      "about": "Sobre nosotros",
      "activities": "Programas",
      "research": "Investigación",
      "resources": "Recursos",
      "contact": "Contacto"
    },
    "cta": "Sumate",
    "language": "Idioma",
    "languages": {
      "en": "English",
      "es": "Español"
    },
    "menu": "Menu",
    "closeMenu": "Cerrar menu",
    "openMenu": "Abrir menu"
  },
  "footer": {
    "copyright": "Todos los derechos reservados.",
    "nav": {
      "about": "Sobre nosotros",
      "activities": "Programas",
      "research": "Investigación",
      "resources": "Recursos",
      "contact": "Contacto",
      "getInvolved": "Participá",
      "privacyPolicy": "Política de privacidad"
    }
  },
  "substack": {
    "eyebrow": "Boletin",
    "title": "Sumate a nuestra lista de correo",
    "description": "Mantenete al tanto de nuestras actividades, eventos y oportunidades.",
    "placeholder": "tu@email.com",
    "button": "Suscribite",
    "disclaimer": "Solo enviaremos correos cuando haya novedades importantes.",
    "success": "¡Te suscribiste! Revisá tu correo para el mensaje de bienvenida.",
    "confirm": "Queda un paso — confirmá la suscripción desde tu bandeja de entrada.",
    "genericError": "Ocurrió un error. Intentá nuevamente.",
    "networkError": "Fallo de conexión. Verificá tu internet e intentalo otra vez."
  },
  "home": {
    "breadcrumb": {
      "home": "Inicio"
    },
    "mission": {
      "eyebrow": "Mision",
      "title": "Asegurando que la IA Beneficie a la Humanidad",
      "paragraph1": "A medida que los modelos de inteligencia artificial avanzan en capacidades{footnote1}, esperamos que tengan un impacto cada vez más profundo en nuestra sociedad{footnote2}. Es esencial que este impacto sea positivo, y que las decisiones tomadas por estos sistemas sean transparentes, confiables y responsables{footnote3} ante las personas afectadas por ellos.",
      "paragraph2": "Creemos que reducir los riesgos asociados a modelos avanzados de IA{footnote4} es uno de los desafíos más importantes de nuestro tiempo. También creemos que es un problema abierto y apasionante{footnote5}, con amplias oportunidades para que más investigadores avancen en este campo{footnote6}.",
      "paragraph3": "La misión de BAISH es apoyar a estudiantes a entrar a este campo y a realizar investigaciones sobre este tema.",
      "cta": "Participá"
    },
    "events": {
      "eyebrow": "Proximos Eventos",
      "title": "Sumate a nuestros talleres y encuentros comunitarios",
      "description": "Mantenete al día con discusiones sobre seguridad en IA, sprints de investigación y espacios colaborativos.",
      "calendarPlaceholder": "El calendario se carga al acercarse a la vista para mantener la carga inicial rápida.",
      "subscribe": "Suscribite al calendario"
    },
    "activities": {
      "title": "Nuestros Programas",
      "description": "Explora los programas recurrentes diseñados para crecer la comunidad de seguridad en IA.",
      "items": {
        "fundamentals": {
          "eyebrow": "Curso",
          "title": "AI Safety Fundamentals",
          "description": "Curso de aula invertida con discusiones semanales sobre alineamiento de IA y mini-proyecto final.",
          "schedule": "Viernes · 14:30",
          "duration": "13 semanas"
        },
        "workshop": {
          "eyebrow": "Taller",
          "title": "AIS Research Workshop",
          "description": "Taller técnico para replicar investigaciones recientes de AI Safety mediante programación.",
          "schedule": "Martes · 14:30",
          "duration": "2.5 hrs"
        },
        "reading": {
          "eyebrow": "Grupo de Lectura",
          "title": "Club del Paper",
          "description": "Presentaciones completas de papers por miembros de la comunidad con grabaciones en YouTube.",
          "schedule": "Jueves alternos · 15h",
          "duration": "2 hrs"
        }
      },
      "joinNow": "Inscribite",
      "joinTelegram": "Sumate al Telegram",
      "learnMore": "Ver más"
    },
    "aisar": {
      "eyebrow": "Proyecto Hermano",
      "title": "Becas AISAR",
      "description": "Programa presencial part-time para estudiantes avanzados que trabajan en proyectos de investigación en AI Safety. Estipendio de $600/mes + presupuesto para cómputo. Temas incluyen interpretabilidad, evaluaciones y supervisión.",
      "duration": "6 meses",
      "commitment": "20 hrs/semana",
      "visitWebsite": "Visitar sitio web"
    },
    "resources": {
      "title": "Recursos",
      "description": "Profundiza en la seguridad de IA con lecturas y herramientas seleccionadas.",
      "items": {
        "reading": {
          "eyebrow": "Recursos",
          "title": "Lecturas Iniciales",
          "description": "Ensayos y papers fundamentales para orientarte en investigación de alineamiento.",
          "meta": "15+ papers"
        },
        "toolkit": {
          "eyebrow": "Recursos",
          "title": "Kit de Herramientas",
          "description": "Repositorios de código, benchmarks y plantillas de experimentos para investigación.",
          "meta": "Herramientas"
        },
        "handbook": {
          "eyebrow": "Recursos",
          "title": "Manual Comunitario",
          "description": "Guía para organizar encuentros y facilitar discusiones productivas.",
          "meta": "Guia"
        }
      },
      "viewResource": "Ver recurso",
      "learnMore": "Ver más"
    },
    "getInvolved": {
      "communityEyebrow": "Comunidad",
      "communityTitle": "Sumate a nuestra comunidad",
      "communityDescription": "Conéctate con estudiantes interesados en la seguridad de IA.",
      "telegramCta": "AI Safety Argentina",
      "telegramMembers": "190+ miembros",
      "whatsappCta": "Comunidad BAISH",
      "whatsappMembers": "140+ miembros"
    }
  },
  "about": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Seguridad en IA"
    },
    "title": "Entendiendo la Seguridad en IA",
    "coreConcepts": {
      "whatIsAiSafety": {
        "title": "¿Que es la Seguridad en IA?",
        "content": "La Seguridad en IA es un campo de investigación enfocado en asegurar que los sistemas avanzados de inteligencia artificial sigan siendo beneficiosos, alineados con los valores humanos y bajo control humano a medida que se vuelven más capaces. Abarca áreas técnicas de investigación como alineamiento, interpretabilidad y robustez, así como consideraciones de gobernanza sobre cómo deberían desarrollarse e implementarse los sistemas de IA."
      },
      "whyItMatters": {
        "title": "¿Por que es Importante?",
        "content": "A medida que los sistemas de IA se vuelven más poderosos y autónomos, pueden desarrollar capacidades que podrían llevar a consecuencias no deseadas si no están diseñados y controlados adecuadamente. Lo que está en juego es importante: la IA avanzada podría ayudar a resolver los mayores desafíos de la humanidad, pero también presenta riesgos significativos si se desarrolla sin medidas de seguridad adecuadas. El campo busca maximizar los beneficios mientras minimiza los daños potenciales."
      },
      "risks": {
        "title": "Riesgos y Desafios Principales",
        "alignment": {
          "title": "Problema de Alineamiento",
          "description": "Asegurar que los sistemas de IA persigan objetivos alineados con los valores e intenciones humanas, incluso cuando se vuelven más capaces."
        },
        "interpretability": {
          "title": "Interpretabilidad",
          "description": "Desarrollar técnicas para entender cómo los sistemas de IA toman decisiones y representan conocimiento."
        },
        "robustness": {
          "title": "Robustez",
          "description": "Crear sistemas que se comporten de manera segura incluso cuando se implementan en nuevos entornos o enfrentan situaciones inesperadas."
        },
        "powerSeeking": {
          "title": "Comportamiento de Busqueda de Poder",
          "description": "Prevenir que los sistemas de IA desarrollen objetivos instrumentales que entren en conflicto con el bienestar humano."
        },
        "coordination": {
          "title": "Desafios de Coordinacion",
          "description": "Garantizar que se mantengan estándares de seguridad en todos los principales esfuerzos de desarrollo de IA a nivel mundial."
        }
      }
    },
    "ourApproach": {
      "title": "Nuestro Enfoque",
      "focusAreas": {
        "title": "Areas de Enfoque",
        "intro": "En BAISH - Buenos Aires AI Safety Hub, nos enfocamos en varias áreas clave dentro de la investigación de seguridad en IA:",
        "items": [
          "Interpretabilidad de Cadena de Pensamiento",
          "Evaluaciones de LLMs",
          "Interpretabilidad mecanica de redes neuronales"
        ]
      },
      "contribution": {
        "title": "Nuestra Contribucion",
        "intro": "Contribuimos al campo a través de:",
        "items": [
          "Apoyando proyectos de investigación estudiantil",
          "Construyendo una comunidad regional de investigadores en seguridad de IA",
          "Organizando talleres, programas de formación y hackathons",
          "Mentoreando a estudiantes interesados en carreras de seguridad en IA"
        ]
      }
    },
    "team": {
      "title": "Equipo Principal",
      "meetTheTeam": "Conoce al Equipo",
      "cofoundersTitle": "Fundadores",
      "leadershiptTitle": "Liderazgo",
      "roles": {
        "coDirector": "Co-director Fundador",
        "commDirector": "Director de Comunicación",
        "headOfStrategy": "Director de Estrategia",
        "advisor": "Advisor"
      },
      "volunteersTitle": "Voluntarios",
      "volunteerRoles": {
        "asfFacilitator": "Facilitador de AI Safety Fundamentals",
        "aisWorkshopFacilitator": "Facilitador del AIS Workshop",
        "programAssistant": "Asistente de Programas"
      },
      "bios": {
        "eitan": "Eitan es investigador de Seguridad en IA a tiempo completo a través del programa {aisarLink} y la {apartLabLink}. Ha sido primer autor de {eitanPaperLink} de Seguridad en IA aceptados en workshops de NeurIPS y coautor de {eitanArxivPaperLink}. Es Licenciado en Física en la Universidad de Buenos Aires. Ha sido asistente de enseñanza en los campamentos de {ml4gLink} en dos ocasiones y ha sido facilitador del {aisesLink} del Center for AI Safety. Actualmente es facilitador del {blueDotAgiLink}.",
        "luca": "Luca ha estado involucrado en Seguridad en IA desde 2016. Después de abandonar una maestría en Ciencias de la Computación en la Universidad de Buenos Aires, recibió becas de {acxLink} y el {ltffLink} para capacitarse en investigación de Seguridad en IA. Ha trabajado en operaciones en {nonlinearLink} y logró el primer lugar en dos sprints separados de {apartResearchLink} y un segundo lugar. Actualmente realiza operaciones a tiempo parcial para el canal de YouTube {aiSpeciesLink}, que ha obtenido más de 14 millones de vistas creando conciencia sobre Seguridad en IA. Actualmente es facilitador del {blueDotAgiLink}."
      }
    },
    "support": {
      "title": "Apoyo Externo",
      "description": "BAISH cuenta con el apoyo de:",
      "openPhilanthropy": {
        "name": "Open Philanthropy",
        "description": "La misión de Open Philanthropy es donar de la manera más efectiva posible para ayudar a otros tanto como sea posible."
      },
      "kairos": {
        "name": "Kairos",
        "program": "Programa Pathfinder",
        "description": "Kairos apoya el desarrollo del campo de seguridad en IA a través de su programa Pathfinder, que ayuda a acelerar iniciativas prometedoras."
      },
      "visitWebsiteCta": "Visitar sitio web",
      "pathfinderCta": "Pathfinder",
      "kairosCta": "Kairos"
    },
    "callToAction": {
      "title": "¿Queres charlar?",
      "description": "Invitamos a cualquier persona interesada en seguridad en IA a agendar una llamada con nosotros.",
      "bookWithEitan": "Reservá con Eitan",
      "bookWithLuca": "Reservá con Luca"
    }
  },
  "activities": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Programas"
    },
    "title": "Nuestros Programas",
    "description": "Sumate a nuestra comunidad y participá en investigación y aprendizaje de seguridad en IA",
    "subscribeCalendar": "Suscribite al calendario de eventos",
    "agiSafety": {
      "title": "AI Safety Fundamentals",
      "status": "Actualmente activo",
      "description": "La actividad consiste en discutir y dar seguimiento de forma presencial a los contenidos del curso de BlueDot: AI Alignment, los cuales deben ser completados de forma asíncrona.",
      "overview": "El curso (extra-oficial) tiene la modalidad de aula invertida. Cada semana, los participantes tendrán que venir con el contenido leído/visto (2-3hs), y los Viernes de 14:30 a 17:00 nos encontraremos presencialmente.",
      "whatToExpect": "Modalidad del Curso",
      "expectations": [
        "13 encuentros en total: 9 conceptuales + 4 de proyecto",
        "Encuentros conceptuales: Discusiones sobre contenidos con dinámicas pre-armadas",
        "Encuentros de proyecto: Mini-proyecto personal con mentoría",
        "2-3 horas semanales de contenido asíncrono",
        "2.5 horas semanales presenciales (Viernes 14:30-17:00)",
        "Certificado de compleción (requiere 7/9 encuentros + proyecto final)"
      ],
      "whoWeSeek": "¿A quienes buscamos?",
      "seekCriteria": [
        "Te interesa abordar conceptos como vulnerabilidades en sistemas de IA o riesgos existenciales",
        "Querés explorar qué oportunidades hay en el campo y tus siguientes pasos a seguir",
        "Estás dispuesto a participar en discusiones abiertas",
        "Tenés buen nivel de inglés",
        "Podes dedicarte a hacer el curso presencialmente (2.5 horas semanales aproximadamente)",
        "Podes dedicarte a realizar las actividades asincrónicas y revisar el material (3 horas semanales aproximadamente)"
      ],
      "programDetails": "Detalles del Programa",
      "duration": "13 semanas",
      "fellowshipPeriod": "Viernes 14:30-17:00",
      "viewCurriculum": "Ver curriculo",
      "applyNow": "Aplicá ahora"
    },
    "aisWorkshop": {
      "title": "AIS Research Workshop",
      "schedule": "Todos los martes @ 14:30",
      "description": "La actividad consiste en discutir y replicar (programando) investigaciones recientes sobre AI Safety de forma presencial para adquirir las habilidades técnicas necesarias para poder investigar de forma independiente.",
      "overview": "Este taller se llevará a cabo los martes de 14:30 a 17:00 y está diseñado para estudiantes que quieren desarrollar habilidades técnicas prácticas en seguridad de IA.",
      "whoWeSeek": "¿A quienes buscamos?",
      "seekCriteria": [
        "Podes dedicarte al menos 5 horas semanales (2 hrs presenciales + 3 hrs asincrónicas)",
        "Tenés buen nivel de inglés",
        "Estás dispuesto a participar en discusiones abiertas",
        "Te interesa adquirir habilidades técnicas sobre ML y Safety",
        "Querés adentrarte en el campo y dar los primeros pasos como investigador"
      ],
      "formatTitle": "Formato del Taller",
      "format": [
        "Sesiones presenciales de 2.5 horas los martes",
        "Discusión de papers recientes de AI Safety",
        "Implementación práctica programando los métodos discutidos",
        "Trabajo asincrónico para familiarizarse con el material (3 hrs/semana)",
        "Mentoría para desarrollar habilidades de investigación independiente"
      ],
      "nextSession": "Proxima Sesion",
      "date": "Consultar calendario",
      "time": "14:30 - 17:00",
      "location": "Pabellon 0+inf, Ciudad Universitaria",
      "topic": "A definir semanalmente",
      "joinTelegram": "Sumate a Telegram para actualizaciones",
      "joinWhatsapp": "Sumate al WhatsApp",
      "applyNow": "Aplicá ahora"
    },
    "paperReading": {
      "title": "Club del Paper",
      "schedule": "Jueves alternos @ 15:00",
      "description": "El Club del Paper presenta papers completos de seguridad en IA e IA en general expuestos por miembros de la comunidad. Cada sesión incluye una presentación profunda seguida de discusión.",
      "overview": "Las presentaciones son grabadas y subidas a nuestro canal de YouTube para que la comunidad pueda revisarlas posteriormente.",
      "selectionCriteriaTitle": "¿Que Esperamos?",
      "criteria": [
        "Presentaciones completas de papers por miembros de la comunidad",
        "Análisis profundo de métodos y resultados",
        "Discusión abierta sobre implicaciones",
        "Grabaciones disponibles en YouTube"
      ],
      "sessionFormatTitle": "Formato de Sesion",
      "format": [
        "Presentación completa del paper (30-40 minutos)",
        "Discusión abierta y preguntas (30-40 minutos)",
        "Sesión grabada y subida a YouTube",
        "Chat de Telegram para coordinación y discusión continua"
      ],
      "nextSession": "Proxima Sesion de Paper",
      "paper": "Consultar en Telegram o calendario",
      "discussionLead": "Miembro de la comunidad",
      "accessList": "Ver grabaciones en YouTube",
      "date": "Consultar calendario",
      "time": "15:00 - 17:00",
      "location": "Pabellon 0+inf, Ciudad Universitaria",
      "youtubeChannel": "Canal de YouTube",
      "telegramGroup": "Grupo de Telegram"
    },
    "common": {
      "duration": "Duracion:",
      "startDate": "Fecha de inicio:",
      "endDate": "Fecha de finalizacion:",
      "applicationDeadline": "Fecha limite de inscripcion:",
      "location": "Ubicacion:",
      "instructors": "Instructores:",
      "fellowshipPeriod": "Periodo de Fellowship:",
      "date": "Fecha:",
      "time": "Hora:",
      "topic": "Tema:",
      "facilitator": "Facilitador:",
      "paper": "Paper:",
      "discussionLead": "Lider de Discusion:"
    },
    "gallery": {
      "eyebrow": "Comunidad",
      "title": "Eventos Pasados",
      "description": "Momentos de nuestros encuentros y actividades recientes"
    },
    "pastPrograms": {
      "title": "Programas anteriores",
      "description": "Reviví nuestros talleres y experiencias pasadas para seguir profundizando.",
      "cards": [
        {
          "eyebrow": "Workshop",
          "title": "Agentic Coding Workshop 2025",
          "description": "Sesión intensiva donde exploramos la metodología BMAD y el trabajo con agentes especializados para shippear software.",
          "date": "3 de octubre de 2025",
          "location": "BAISH x Y-hat · Salas 1109 y 1110",
          "slug": "agentic-coding-workshop",
          "cta": "Ver materiales",
          "link": "/agentic-coding-workshop"
        }
      ]
    },
    "sisterProjects": {
      "title": "Proyectos Hermanos",
      "description": "Iniciativas colaborativas que avanzan la seguridad de IA en América Latina"
    },
    "lanais": {
      "eyebrow": "Proyecto Hermano",
      "title": "LANAIS",
      "subtitle": "Red Latinoamericana de Seguridad en IA",
      "description": "Conectando investigadores y responsables de políticas para el desarrollo seguro de inteligencia artificial en América Latina. LANAIS mantiene un directorio de expertos en seguridad de IA en toda la región y opera en inglés, español y portugués.",
      "visitWebsite": "Visitar sitio web"
    },
    "fair": {
      "eyebrow": "Proyecto Hermano",
      "title": "FAIR",
      "subtitle": "Frontier Artificial Intelligence Research",
      "description": "Organización de investigación en seguridad de IA de la Universidad de Buenos Aires que avanza la seguridad de IA de frontera mediante investigación de alto impacto. Áreas de enfoque incluyen alineamiento de IA, riesgos existenciales, gobernanza y evaluaciones de sistemas.",
      "visitWebsite": "Visitar sitio web"
    }
  },
  "contact": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Contacto"
    },
    "title": "Contactanos",
    "description": "Comunicate con la comunidad de BAISH",
    "linkText": {
      "resourcesPage": "página de Recursos"
    },
    "cards": {
      "telegram": {
        "title": "Telegram",
        "description": "Sumate a nuestro canal de comunidad para discusiones y actualizaciones:"
      },
      "location": {
        "eyebrow": "Visitanos",
        "title": "Ubicacion",
        "description": "Estamos ubicados en el Departamento de Ciencias de la Computación:"
      },
      "social": {
        "eyebrow": "Social",
        "title": "Redes Sociales",
        "description": "Seguinos para actualizaciones y anuncios:"
      }
    },
    "form": {
      "eyebrow": "Contacto",
      "title": "Contactanos",
      "description": "Comunicate con la comunidad de BAISH",
      "nameLabel": "¿Cuál es tu nombre?",
      "emailLabel": "¿Cuál es tu correo electrónico?",
      "messageLabel": "Mensaje",
      "clearForm": "Limpiar formulario",
      "submit": "Enviá"
    },
    "getInvolved": {
      "title": "Sumate",
      "description": "Hay múltiples formas de participar en nuestra comunidad y actividades.",
      "newsletter": {
        "title": "Suscribite a nuestra lista de correo",
        "description": "Mantenete al día con nuestros eventos, actividades y oportunidades suscribiéndote a nuestra lista de correo. Te enviamos newsletters mensuales y anuncios importantes."
      }
    },
    "faq": {
      "title": "Preguntas Frecuentes",
      "items": [
        {
          "question": "¿Necesito ser estudiante de la UBA para participar?",
          "answer": "¡No! Si bien estamos basados en la UBA, nuestras actividades están abiertas a todos los interesados en la seguridad de la IA, independientemente de su afiliación universitaria."
        },
        {
          "question": "¿Qué formación necesito para unirme a sus actividades?",
          "answer": "Depende de la actividad. Algunas, como nuestros grupos de discusión, están abiertas a cualquier persona independientemente de su formación técnica. Otras, como nuestros cursos técnicos, pueden requerir conocimientos de programación o familiaridad con conceptos de aprendizaje automático."
        },
        {
          "question": "¿Sus actividades se realizan en inglés o español?",
          "answer": "La mayoría de nuestras actividades se realizan en español, pero ocasionalmente tenemos sesiones en inglés, especialmente cuando recibimos oradores internacionales. Verifica los detalles del evento específico para obtener información sobre el idioma."
        },
        {
          "question": "¿Cómo puedo empezar a aprender sobre seguridad de IA si soy completamente nuevo en el campo?",
          "answer": "Recomendamos comenzar con nuestra {resourcesLink}, que tiene materiales seleccionados organizados por nivel de dificultad. También puedes unirte a nuestro grupo de discusión semanal para aprender junto con otros miembros de la comunidad."
        },
        {
          "question": "¿Puedo proponer una nueva actividad o dirección de investigación?",
          "answer": "¡Por supuesto! Siempre estamos abiertos a nuevas ideas y colaboraciones. Por favor completa el formulario de contacto arriba con tu propuesta."
        }
      ]
    }
  },
  "research": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Investigación"
    },
    "title": "Nuestra Investigación",
    "filterBy": "Filtrar por:",
    "filters": {
      "all": "Todos",
      "interpretability": "Interpretabilidad",
      "alignment": "Alineamiento",
      "robustness": "Robustez",
      "valueLearning": "Aprendizaje de Valores"
    },
    "approachTitle": "Enfoque de Investigacion",
    "focusAreasTitle": "Areas de Enfoque",
    "focusAreas": {
      "mechInterp": "Interpretabilidad Mecánica - Entender cómo las redes neuronales procesan información internamente",
      "alignment": "Alineamiento de IA - Asegurar que los sistemas de IA actúen de acuerdo a valores e intenciones humanas",
      "robustness": "Robustez y Pruebas Adversarias - Construir sistemas resilientes resistentes a ataques",
      "valueLearning": "Aprendizaje de Valores - Enseñar a los sistemas de IA a aprender y respetar preferencias humanas"
    },
    "projectsTitle": "Proyectos de Investigacion",
    "linkPlaceholder": "Enlace",
    "publicationsTitle": "Publicaciones",
    "ongoingTitle": "Investigacion en Curso",
    "started": "Iniciado",
    "expectedCompletion": "Finalizacion Esperada",
    "intro": "Descubri como el equipo de investigacion de BAISH explora interpretabilidad, alineamiento, robustez y aprendizaje de valores para mantener segura a la IA de frontera.",
    "overview": {
      "paragraphs": [
        "Prototipamos sprints colaborativos enfocados en interpretabilidad mecanica, evaluaciones y teoria de alineamiento a los que se pueden sumar estudiantes locales.",
        "Buscamos que Buenos Aires contribuya de forma consistente al trabajo global de seguridad en IA y publicar recursos abiertos que otros equipos puedan reutilizar."
      ]
    },
    "publicationsIntro": "Seleccion de articulos, preprints y envios a workshops del network de BAISH.",
    "publications": [
      {
        "title": "Tracing Gradient Circuits in Sparse Autoencoders",
        "authors": "Eitan Braun, Luca Sambucci",
        "venue": "NeurIPS AI Safety Workshop · 2024",
        "links": [
          {
            "label": "Paper",
            "url": "#"
          },
          {
            "label": "Slides",
            "url": "#"
          }
        ]
      },
      {
        "title": "Alignment Case Studies for Spanish-Speaking Teams",
        "authors": "Martina Lopez, Tomas Villar",
        "venue": "BAISH Research Notes · 2025",
        "links": [
          {
            "label": "Leer",
            "url": "#"
          }
        ]
      },
      {
        "title": "Learning from Mechanistic Feature Drift",
        "authors": "Ana Paredes, Facundo Ibarra",
        "venue": "BAIR Interpretability Sprint · 2025",
        "links": [
          {
            "label": "Resumen",
            "url": "#"
          },
          {
            "label": "Repo",
            "url": "#"
          },
          {
            "label": "Video",
            "url": "#"
          }
        ]
      }
    ],
    "ongoingDescription": "Instantanea de lineas de trabajo que hoy buscan colaboradores o mentores.",
    "ongoingProjects": [
      {
        "title": "Circuit Breakers for Speculative Decoding",
        "researchers": "Eitan Braun, Sofia Molina",
        "completion": "45% completo",
        "description": "Evaluamos como el speculative decoding cambia modos de falla en asistentes multilingues y construimos mitigaciones.",
        "started": "Enero 2025",
        "expectedCompletion": "Mayo 2025"
      },
      {
        "title": "Human Feedback Benchmarks in Spanish",
        "researchers": "Juan Perez, Camila Torres",
        "completion": "30% completo",
        "description": "Recolectamos datos de preferencias estilo RLHF en espanol para evaluar modelos abiertos en prompts culturales.",
        "started": "Noviembre 2024",
        "expectedCompletion": "Junio 2025"
      },
      {
        "title": "Agentic Eval Harness for Open Models",
        "researchers": "Maria Fuentes, Diego Catalan",
        "completion": "70% completo",
        "description": "Construimos un harness liviano para testear agentes tipo auto-GPT frente a mal uso de herramientas y drift de objetivos.",
        "started": "Agosto 2024",
        "expectedCompletion": "Marzo 2025"
      }
    ],
    "projects": [
      {
        "title": "Mechanistic Feature Cartography",
        "year": "2025",
        "researchers": "Eitan Braun, Azul Fernandez",
        "abstract": "Mapeamos circuitos neuronales en Llama 3 70B para crear demos de interpretabilidad en espanol.",
        "category": "interpretability",
        "tag": "Interpretabilidad"
      },
      {
        "title": "Speculative Decoding Safety",
        "year": "2025",
        "researchers": "Luca Sambucci, Florencia Neme",
        "abstract": "Evaluamos modos de falla en pipelines de speculative decoding para despliegues sensibles a alineamiento.",
        "category": "alignment",
        "tag": "Alineamiento"
      },
      {
        "title": "Robust Benchmark Translation",
        "year": "2024",
        "researchers": "Martina Lopez, Diego Catalan",
        "abstract": "Adaptamos datasets de QA adversarial al espanol para estresar asistentes bilingues.",
        "category": "robustness",
        "tag": "Robustez"
      },
      {
        "title": "Interpretability Tooling Sprint",
        "year": "2024",
        "researchers": "Agustin Rivas, Tomas Villar",
        "abstract": "Construimos herramientas livianas que visualizan heads de atencion transformer para investigadores locales.",
        "category": "interpretability",
        "tag": "Interpretabilidad"
      },
      {
        "title": "Value Learning Case Library",
        "year": "2023",
        "researchers": "Tamara Ponce, Ivan Mazzino",
        "abstract": "Documentamos escenarios concretos de alineamiento para equipos de politicas en Latam.",
        "category": "value-learning",
        "tag": "Aprendizaje de Valores"
      },
      {
        "title": "Alignment Reading Reports",
        "year": "2022",
        "researchers": "Community Fellows",
        "abstract": "Resenias tecnicas cortas del club de lectura de BAISH sobre papers nuevos de gobernanza y seguridad.",
        "category": "alignment",
        "tag": "Alineamiento"
      }
    ]
  },
  "resources": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Recursos"
    },
    "title": "Recursos de Aprendizaje",
    "description": "Materiales curados para explorar conceptos de seguridad en IA",
    "sections": {
      "featuredVideo": {
        "title": "Introduccion a la Seguridad en IA",
        "description": "Empieza aquí: Por qué los expertos temen la IA superinteligente – y qué podemos hacer al respecto"
      },
      "selfStudy": {
        "title": "Autoestudio",
        "lastUpdated": "Ultima actualizacion: 22 de octubre de 2025",
        "description": "Estos currículos y listas de lectura te permiten profundizar en la seguridad de IA a través del aprendizaje independiente.",
        "fundamentalReading": {
          "title": "Lecturas fundamentales",
          "items": [
            {
              "name": "AI Alignment Forum: Secuencias Curadas",
              "description": "Lista de secuencias curadas por el equipo del AI Alignment Forum, con trabajos de Richard Ngo, Paul Christiano, etc.",
              "category": "Alineacion Tecnica",
              "createdBy": "Varios",
              "url": "https://www.alignmentforum.org/library"
            }
          ]
        },
        "standardCourses": {
          "title": "Cursos introductorios estandar",
          "items": [
            {
              "name": "BlueDot Impact: Alineación y Gobernanza",
              "description": "Cubre conceptos clave y perspectivas de investigación en seguridad de IA, divididos en dos áreas principales: Alineación y Gobernanza. Anteriormente conocido como AI Safety Fundamentals.",
              "category": "Alineacion Tecnica, Gobernanza",
              "createdBy": "BlueDot Impact",
              "url": "https://bluedot.org/courses"
            }
          ]
        },
        "relatedResources": {
          "title": "Recursos relacionados",
          "eventsTraining": {
            "title": "Eventos y capacitacion",
            "description": "Próximas becas, conferencias, cursos facilitados, etc.",
            "url": "https://www.aisafety.com/events-and-training"
          },
          "aiDigest": {
            "title": "AI Digest",
            "description": "Explicaciones interactivas de capacidades y tendencias de IA",
            "url": "https://theaidigest.org/"
          }
        }
      },
      "externalOpportunities": {
        "title": "Oportunidades de Capacitacion Externa",
        "subtitle": "Proximos cursos, talleres y programas de organizaciones de todo el mundo",
        "description": "Hay una amplia gama de eventos y programas de capacitación en seguridad de IA, tanto online como presenciales. Estos te pueden ayudar a desarrollar habilidades, hacer conexiones y descubrir oportunidades.",
        "newsletter": {
          "title": "Suscribite al Newsletter de Nuevas Oportunidades",
          "description": "Recibí un email semanal resumiendo todos los nuevos eventos y programas de capacitacion",
          "cta": "Suscribite"
        },
        "timeline": {
          "title": "Cronograma de convocatorias abiertas",
          "loading": "Cargando cronograma..."
        }
      }
    }
  },
  "privacyPolicy": {
    "breadcrumb": {
      "home": "Inicio",
      "current": "Política de Privacidad"
    },
    "title": "Política de Privacidad",
    "sections": {
      "approach": {
        "title": "Nuestro Enfoque de Privacidad",
        "content": "En BAISH (Buenos Aires AI Safety Hub), estamos comprometidos a respetar tu privacidad. Esta Política de Privacidad describe nuestras prácticas con respecto a la recopilación, uso y protección de tu información cuando utilizas nuestro sitio web y servicios."
      },
      "dataCollection": {
        "title": "Recopilacion de Datos",
        "content": "Recopilamos información personal mínima. Los únicos datos personales que recopilamos son las direcciones de correo electrónico cuando los usuarios se registran voluntariamente para recibir nuestro boletín a través de Substack. Esta información es almacenada y gestionada por Substack de acuerdo con su política de privacidad."
      },
      "noTracking": {
        "title": "Sin Seguimiento ni Cookies",
        "content": "No utilizamos cookies, análisis, herramientas de seguimiento ni ninguna otra tecnología para recopilar datos sobre ti. No monitoreamos tus actividades de navegación ni recopilamos información sobre tus comportamientos en línea."
      },
      "thirdParty": {
        "title": "Servicios de Terceros",
        "content": "Nuestro boletín se gestiona a través de Substack. Cuando te suscribes a nuestro boletín, tu dirección de correo electrónico se comparte y almacena con Substack. Consulta la",
        "substackLink": "Política de Privacidad de Substack",
        "content2": "para comprender cómo manejan tu información."
      },
      "rights": {
        "title": "Tus Derechos",
        "content": "Tienes derecho a cancelar la suscripción a nuestro boletín en cualquier momento haciendo clic en el enlace para cancelar la suscripción en cualquiera de nuestros correos electrónicos o contactándonos directamente. Si tienes alguna pregunta sobre tus datos o deseas acceder, corregir o eliminar tu información, contáctanos."
      },
      "changes": {
        "title": "Cambios a Esta Politica",
        "content": "Podemos actualizar esta Política de Privacidad de vez en cuando. Te notificaremos cualquier cambio publicando la nueva Política de Privacidad en esta página."
      },
      "contact": {
        "title": "Contactanos",
        "content": "Si tienes alguna pregunta sobre esta Política de Privacidad, contáctanos a través de nuestra",
        "contactLink": "página de Contacto"
      }
    }
  },
  "agenticCodingWorkshop": {
    "metadata": {
      "title": "Agentic Coding Workshop — BAISH",
      "description": "Todo el material del workshop de Agentic Coding: metodología BMAD, agentes, workflows, y recursos para empezar inmediatamente.",
      "openGraph": {
        "title": "Agentic Coding Workshop — BAISH",
        "description": "Metodología completa de agentic coding (BMAD) con agentes, workflows, y recursos prácticos."
      },
      "twitter": {
        "title": "Agentic Coding Workshop — BAISH",
        "description": "Metodología completa de agentic coding (BMAD) con agentes, workflows, y recursos prácticos."
      }
    },
    "nav": {
      "overview": "Resumen",
      "problem": "Problema",
      "solution": "Solución",
      "agents": "Agentes",
      "planning": "Planning",
      "development": "Development",
      "resources": "Recursos"
    },
    "breadcrumb": {
      "home": "Inicio",
      "current": "Agentic Coding Workshop"
    },
    "hero": {
      "title": "Workshop de Agentic Coding",
      "tagline": "Armá proyectos con AI como si tuvieras todo un equipo: metodología BMAD, agentes, procesos y herramientas listas para usar.",
      "eventDetails": "Viernes 3 de octubre 2025, 16:00hs · Salas 1109 y 1110 — BAISH x Y-hat",
      "note": "Esta página reúne todos los materiales y recursos del workshop.",
      "whatsapp": "Unite al grupo de WhatsApp \"Agentic Coding\" dentro de la comunidad BAISH para discutir ideas, compartir proyectos y pedir ayuda con BMAD.",
      "buttons": {
        "startNow": "Empezar ahora",
        "baish": "BAISH",
        "yHat": "Y-hat",
        "joinWhatsapp": "Unirse al WhatsApp",
        "viewResources": "Ver recursos"
      }
    },
    "problem": {
      "eyebrow": "Contexto",
      "title": "El problema con los LLMs tradicionales",
      "description": "Dos obstáculos hacen que “darle todo al modelo” no funcione: degradación en contextos largos y falta de memoria real a través del tiempo.",
      "sourcePrefix": "Fuente:",
      "cards": {
        "contextDegradation": {
          "title": "Degradación con contexto largo",
          "description": "El benchmark LoCoDiff (enero 2025) muestra que incluso el mejor modelo disponible, Sonnet 4.5, degrada significativamente con contextos largos.",
          "highlight": "El resultado: de 96 % de precisión con contextos de 2 K–21 K tokens a 64 % con más de 60 K tokens. Cuando le das todo tu codebase al modelo, se ahoga en información.",
          "details": [
            "Los modelos de punta siguen dependiendo de ventanas de contexto manejables para mantener la precisión.",
            "Darles archivos completos o repositorios enteros produce ruido, repeticiones y decisiones inconsistentes."
          ],
          "sourceLabel": "LoCoDiff Benchmark"
        },
        "lackOfLongTermMemory": {
          "title": "Sin memoria a largo plazo",
          "description": "Un estudio de METR (julio 2025) demostró que developers expertos con 2+ años de experiencia en sus propios proyectos fueron 20 % más lentos usando AI que trabajando solos.",
          "highlight": "¿Por qué? El LLM arranca de cero cada vez: no tiene el contexto tácito que las personas acumulan. Los expertos predijeron que serían 39 % más rápidos, pero la realidad fue lo opuesto.",
          "details": [
            "Tiempo observado por story: 1.67 h sin AI vs 2.26 h con AI asistida.",
            "Predicciones previas esperaban reducciones de 24 %–39 %, exponiendo la brecha entre expectativas y realidad."
          ],
          "sourceLabel": "METR AI R&D Study (July 2025)"
        }
      }
    },
    "solution": {
      "eyebrow": "Método BMAD",
      "title": "La solución: un equipo agentic que planifica y ejecuta",
      "description": "BMAD es un método de desarrollo con AI donde ocho agentes especializados trabajan como un equipo real. Planifican todo el proyecto antes de codear y luego ejecutan story por story con validaciones continuas.",
      "description2": "Cada agente es el mismo LLM con un prompt especializado y acceso a contexto shardeado y verificado. No hay memoria mágica: hay documentación estructurada al alcance justo.",
      "calloutTitle": "¿Por qué funciona BMAD?",
      "cards": {
        "sharding": {
          "title": "Sharding",
          "description": "Documentos grandes se dividen en fragmentos pequeños y enfocados. En vez de darle al Developer un PRD de 10 000 tokens, recibe un shard de 400–600 tokens con lo esencial para la story.",
          "outcome": "Resultado: cada agente opera en la zona de 96 % de precisión (<5 K tokens) sin ruido adicional."
        },
        "specializedAgents": {
          "title": "Agentes especializados",
          "description": "Ocho agentes con roles concretos: Product Manager, Architect, Developer, QA, etc. Cada uno tiene instrucciones y checklist propios, y consulta solamente el contexto que necesita.",
          "outcome": "Resultado: contexto quirúrgicamente preciso para cada decisión, sin sobrecargar al modelo."
        },
        "structuredDocumentation": {
          "title": "Documentación estructurada",
          "description": "Planning riguroso antes de codear: PRD completo, arquitectura definida y stories secuenciales que se validan entre sí. Eso crea la “memoria” que los LLMs no tienen.",
          "outcome": "Resultado: los agentes trabajan con información profesional y verificable, siempre alineada con el objetivo del proyecto."
        }
      },
      "reasons": {
        "optimizedContext": {
          "title": "1. Contexto optimizado",
          "description": "En el estudio METR los equipos trabajaron con codebases enormes en Cursor y terminaron 20 % más lentos. BMAD hace lo contrario: el PM trabaja con 2 K tokens de requirements, Arquitectura con ~3 K tokens y el Developer con un único epic (1.5 K tokens). Precisión alta, sin degradación."
        },
        "validationTransparency": {
          "title": "2. Validaciones y transparencia",
          "description": "El Product Owner valida cada story draft antes de pasar a desarrollo, el QA revisa el trabajo del Developer y el equipo humano aprueba cada hito. Los artefactos son legibles por humanos y quedan versionados en el repo."
        },
        "advancedElicitation": {
          "title": "3. Elicitación avanzada",
          "description": "Los agentes hacen preguntas y completan documentación iterativamente. No es solo generar código: descubren, clarifican y actualizan requirements manteniendo a la persona en el loop."
        }
      }
    },
    "agentsSection": {
      "eyebrow": "Equipo Agentic",
      "title": "Los ocho agentes de BMAD",
      "description": "Cada rol es el mismo modelo con un prompt especializado y contexto shardeado. El resultado: un equipo multidisciplinario que trabaja como si fuera humano.",
      "artifactsLabel": "Artefactos"
    },
    "agents": {
      "businessAnalyst": {
        "name": "Business Analyst",
        "role": "Insightful Analyst & Strategic Ideation Partner",
        "description": "Market research, brainstorming, competitive analysis, creación de project briefs y documentación de proyectos brownfield.",
        "artifacts": [
          "Project brief",
          "Market research",
          "Competitor analysis",
          "Brainstorming output"
        ]
      },
      "productManager": {
        "name": "Product Manager",
        "role": "Investigative Product Strategist & Market-Savvy PM",
        "description": "Crea PRDs, define estrategia de producto, prioriza features y mantiene alineados a los stakeholders. Paso obligatorio del método.",
        "artifacts": ["PRD (Product Requirements Document)", "Brownfield PRD"]
      },
      "architect": {
        "name": "Architect",
        "role": "Holistic System Architect & Full-Stack Technical Leader",
        "description": "Diseño de sistemas, arquitectura técnica, selección de tecnologías, contratos de API y planes de infraestructura. Paso obligatorio del método.",
        "artifacts": [
          "Full-stack architecture",
          "Backend architecture",
          "Frontend architecture",
          "Brownfield architecture"
        ]
      },
      "uxExpert": {
        "name": "UX Expert",
        "role": "User Experience Designer & UI Specialist",
        "description": "Diseño UI/UX, wireframes, prototipos, front-end specifications y prompts listos para v0 o Lovable.",
        "artifacts": ["Front-end spec", "UI design prompts"]
      },
      "productOwner": {
        "name": "Product Owner",
        "role": "Technical Product Owner & Process Steward",
        "description": "Gestiona el backlog, refina historias, define acceptance criteria y valida la coherencia entre artefactos. Crítico: el sharding evita la degradación del modelo.",
        "artifacts": ["Sharded documents", "Epic files", "Story validations"]
      },
      "scrumMaster": {
        "name": "Scrum Master",
        "role": "Technical Scrum Master & Story Preparation Specialist",
        "description": "Prepara historias claras, gestiona epics, dirige retros y mantiene la cadencia ágil. Produce drafts listos para que el Developer implemente sin fricción.",
        "artifacts": [
          "User story drafts",
          "Sequential tasks",
          "Acceptance criteria"
        ]
      },
      "developer": {
        "name": "Developer",
        "role": "Expert Senior Software Engineer & Implementation Specialist",
        "description": "Implementa código, cubre tests, refactoriza y documenta decisiones. Trabaja story por story con cobertura de pruebas.",
        "artifacts": [
          "Production code",
          "Unit tests",
          "Integration tests",
          "E2E tests",
          "Code documentation"
        ]
      },
      "qa": {
        "name": "QA",
        "role": "Test Architect with Quality Advisory Authority",
        "description": "Define estrategias de testing, evalúa riesgos, asegura trazabilidad de requirements y emite la decisión de calidad final.",
        "artifacts": [
          "QA results & gate decisions",
          "Risk profiles",
          "Test plans & design",
          "Requirements tracing",
          "NFR assessments"
        ]
      }
    },
    "commands": {
      "eyebrow": "Operativa diaria",
      "title": "Cómo se usan los comandos",
      "description": "Los agentes se invocan por terminal o en el IDE usando comandos cortos. En todos los casos pasás el contexto con @archivo.md.",
      "syntax": {
        "title": "Sintaxis de comandos",
        "description": "Elegí la herramienta que uses y seguí la misma estructura: comando + acción + archivos relevantes.",
        "blocks": {
          "claudeOpencode": {
            "heading": "Claude Code / OpenCode"
          },
          "cursorWindsurf": {
            "heading": "Cursor / Windsurf"
          }
        }
      },
      "switch": {
        "title": "Cambiar de agente sin ruido",
        "description": "Cada agente opera en su propio contexto. Para alternar sin confusiones:",
        "steps": [
          "Limpia el contexto con /clear (Claude Code) o /new (OpenCode).",
          "Invocá el agente con su comando de inicialización (ej: /po *shard-doc).",
          "Pasale únicamente los archivos relevantes usando @filename.md."
        ],
        "tip": {
          "prefix": "Tip:",
          "beforeDocs": "Mantené tus documentos en",
          "beforeExample": "y usá nombres claros (ej.",
          "afterExample": ") para shardear contexto con precisión."
        }
      }
    },
    "planning": {
      "eyebrow": "Fase 1",
      "title": "Planning (una sola vez al inicio)",
      "description": "Diseño completo antes de escribir código. Todo se ejecuta desde la terminal con comandos BMAD.",
      "steps": {
        "pmPrdCreation": {
          "title": "PM: PRD Creation",
          "summary": "El Product Manager crea el Product Requirements Document guiando al usuario sección por sección.",
          "bullets": [
            "Proceso interactivo: el PM hace preguntas y captura respuestas a medida que avanza.",
            "Define features y epics (solo títulos de stories en esta fase).",
            "Detalla requirements funcionales y no funcionales.",
            "Prioriza MVP vs roadmap y captura dependencias clave.",
            "Cada sección se revisa y aprueba antes de continuar."
          ],
          "callout": {
            "title": "Nota importante",
            "text": "Las stories en el PRD son breves (solo títulos). Más adelante el Scrum Master las expandirá con tareas detalladas."
          }
        },
        "architectDesign": {
          "title": "Architect: System Design",
          "summary": "El Architect lee el PRD y diseña la arquitectura técnica completa, siempre de forma interactiva.",
          "bullets": [
            "Selecciona tech stack para frontend, backend y base de datos.",
            "Define la estructura de carpetas y organización del código.",
            "Diseña APIs y contratos entre componentes.",
            "Cubre escalabilidad, seguridad, observabilidad y performance.",
            "Cada sección se valida con el usuario antes de avanzar."
          ]
        },
        "poChecklist": {
          "title": "PO: Master Checklist",
          "summary": "El Product Owner valida que PRD y arquitectura estén perfectamente alineados antes de sharding.",
          "bullets": [
            "Verifica coherencia entre requirements y diseño técnico.",
            "Confirma que la arquitectura permite implementar todos los features priorizados.",
            "Identifica gaps, contradicciones o riesgos que deben resolverse antes de continuar."
          ],
          "callout": {
            "title": "Si algo no cierra",
            "text": "Se refinan los documentos hasta que todo tenga sentido. No se pasa a la siguiente fase sin validación completa."
          }
        },
        "poSharding": {
          "title": "PO: Sharding",
          "summary": "El Product Owner ejecuta el sharding de PRD y Arquitectura en epics y stories manejables (<2 K tokens).",
          "bullets": [
            "Corre el programa de terminal que divide automáticamente los documentos.",
            "Genera shards pequeños ubicados en docs/epics y docs/stories.",
            "Cada archivo contiene contexto enfocado y se guarda como Markdown versionable.",
            "Ejemplo: un PRD grande se transforma en docs/epics/epic-1-auth.md, docs/epics/epic-2-dashboard.md, etc."
          ],
          "callout": {
            "title": "Resultado",
            "text": "Backlog priorizado, con stories shardeadas y listas para desarrollo iterativo."
          }
        }
      },
      "optionalAgentsTitle": "Agentes adicionales según necesidad",
      "optionalAgents": [
        "Business Analyst: investigaciones greenfield y project brief inicial.",
        "UX Expert: specs de interfaz y prompts para herramientas como v0 o Lovable.",
        "QA: perfila riesgos y criterios de calidad antes de empezar el desarrollo."
      ],
      "summaryTitle": "Al finalizar planning tenés:",
      "summaryPoints": [
        "PRD completo y validado.",
        "Arquitectura definida y alineada con el PRD.",
        "Backlog de stories shardeadas y priorizadas.",
        "Contexto estructurado y versionado para todo el equipo."
      ],
      "summaryNote": "No escribiste una línea de código todavía. Ese enfoque intencional evita semanas de refactorings más adelante."
    },
    "development": {
      "eyebrow": "Fase 2",
      "title": "Development loop iterativo",
      "description": "Implementación story por story con validaciones integradas. Repetí este loop hasta completar tu backlog.",
      "steps": {
        "smReviewNotes": {
          "title": "SM: Review previous notes",
          "summary": "El Scrum Master repasa las notas de la story anterior para arrancar con aprendizaje acumulado.",
          "bullets": [
            "Identifica qué funcionó y qué no funcionó.",
            "Recupera decisiones técnicas importantes.",
            "Revisa feedback del Developer y del QA.",
            "Documenta aprendizajes para aplicar en la próxima story."
          ],
          "callouts": [
            {
              "title": "Loop de aprendizaje",
              "text": "Las notas de hoy alimentan el draft de mañana. El equipo mejora story tras story."
            }
          ]
        },
        "smDraftNextStory": {
          "title": "SM: Draft next story",
          "summary": "El Scrum Master arma el draft de la próxima story usando únicamente el contexto relevante.",
          "bullets": [
            "Lee solo el epic correspondiente (no todo el PRD).",
            "Revisa la arquitectura y el PRD en la medida justa.",
            "Genera tareas secuenciales muy claras.",
            "Define criterios de aceptación específicos.",
            "Incluye suficiente contexto sin ahogar al modelo."
          ]
        },
        "poValidateDraft": {
          "title": "PO: Validate story draft",
          "summary": "El Product Owner valida el draft con el PRD para asegurar coherencia antes de codear.",
          "bullets": [
            "Chequea que el draft coincida con los objetivos originales.",
            "Confirma que todos los requirements estén cubiertos.",
            "Señala gaps o contradicciones para corrección inmediata.",
            "Puede aportar recomendaciones al Scrum Master."
          ],
          "callouts": [
            {
              "title": "Check de alineación",
              "text": "Garantiza que el Developer implemente exactamente lo acordado en planning."
            }
          ]
        },
        "devImplementation": {
          "title": "Dev: Implementation",
          "summary": "El Developer implementa la story completa siguiendo arquitectura, UX y checklist de pruebas.",
          "bullets": [
            "Produce código de producción alineado con la arquitectura.",
            "Escribe tests unitarios, de integración y E2E según corresponda.",
            "Cubre manejo de errores y edge cases.",
            "Puede invocar MCPs como Playwright para automatizar pruebas end-to-end."
          ]
        },
        "qaReview": {
          "title": "QA: Test story thoroughly",
          "summary": "El QA ejerce el rol de gatekeeper de calidad antes de que la story avance.",
          "bullets": [
            "Ejecuta todos los tests (unitarios, integración, E2E).",
            "Realiza testing manual sobre user flows y edge cases.",
            "Verifica que se cumplan los criterios de aceptación.",
            "Perfila riesgos (seguridad, performance, fiabilidad).",
            "Emite veredicto: PASS (todo ok) / CONCERNS (revisar) / FAIL (crítico) / WAIVED (aceptado explícitamente)."
          ],
          "callouts": [
            {
              "title": "Quality gates",
              "text": "PASS (todo ok) • CONCERNS (señales leves) • FAIL (problema crítico) • WAIVED (riesgo aceptado explícitamente)."
            },
            {
              "title": "Check crítico",
              "text": "El QA asegura que el código funciona y cumple estándares profesionales antes de pasar a producción."
            }
          ]
        },
        "devFixes": {
          "title": "Dev: Fix according to QA review",
          "summary": "El Developer corrige según el reporte del QA y deja todo en estado PASS.",
          "bullets": [
            "Revisa el resultado del QA (PASS/CONCERNS/FAIL).",
            "Implementa fixes y mejoras puntuales.",
            "Resuelve cada CONCERN y FAIL registrado.",
            "Reejecuta los tests para confirmar que nada se rompe."
          ],
          "callouts": [
            {
              "title": "Iterativo",
              "text": "Si el QA emitió FAIL, se repite la revisión hasta obtener PASS o WAIVED."
            }
          ]
        },
        "markDone": {
          "title": "Mark done & next story",
          "summary": "Se cierra la story y el equipo vuelve al paso 1 con la siguiente prioridad.",
          "bullets": [
            "Actualiza el backlog marcando la story como done.",
            "Elige la siguiente story del backlog priorizado.",
            "Vuelve al paso 1: el SM revisa las notas recién escritas."
          ],
          "callouts": [
            {
              "title": "Loop iterativo",
              "text": "Story por story, commit por commit, hasta completar el proyecto."
            }
          ]
        }
      },
      "loopReminder": "Este loop se repite: volvés al paso 1 con la próxima story.",
      "notesTitle": "Notas sobre el proceso",
      "notes": [
        "Validaciones integradas: PO valida antes de codear, QA testea después, Developer corrige y documenta.",
        "Flexibilidad de calidad: podés aceptar CONCERNS en un MVP o exigir PASS en software crítico.",
        "Loop de aprendizaje continuo: las notas del Developer alimentan al SM en la siguiente iteración."
      ],
      "advantagesTitle": "Ventajas del loop iterativo",
      "advantagesPoints": [
        "Siempre tenés una versión funcional y testeada después de cada story.",
        "Podés pivotar rápido: cada ciclo entrega valor independiente.",
        "El aprendizaje se acumula con notas y retrospectivas cortas.",
        "La persona sigue en control: aprueba cada transición clave."
      ]
    },
    "resources": {
      "eyebrow": "Recursos",
      "title": "Todo para empezar hoy mismo",
      "description": "Herramientas, plantillas y guías para ejecutar BMAD sin fricción.",
      "toolingTitle": "¿Qué herramienta usar?",
      "toolOptions": {
        "claudeCode": {
          "title": "Claude Code",
          "highlight": "Mejor opción: herramienta oficial de Anthropic con Sonnet 4.5 (top del benchmark).",
          "bullets": [
            "Máxima calidad",
            "Integración perfecta",
            "$100/mes (Max Plan)"
          ]
        },
        "openCode": {
          "title": "OpenCode",
          "highlight": "Más versátil: te logueás con tu proveedor y usa ese plan.",
          "bullets": [
            "Login con Anthropic, GitHub Copilot, Z.ai, etc.",
            "Usa el plan de tu proveedor",
            "Open source y multi-modelo"
          ],
          "note": "Requiere workaround (ver más abajo)."
        },
        "cursorWindsurf": {
          "title": "Cursor / Windsurf",
          "highlight": "IDEs populares que soportan BMAD con sintaxis @mention.",
          "bullets": [
            "Editores completos",
            "Comunidad grande",
            "Sintaxis @agent"
          ]
        },
        "geminiCli": {
          "title": "Gemini CLI",
          "highlight": "Gratis: Gemini 2.5 Pro con soporte oficial BMAD.",
          "bullets": [
            "Gemini 2.5 Pro",
            "Uso gratuito incluido",
            "Soporte oficial BMAD"
          ]
        },
        "droidCli": {
          "title": "Droid CLI",
          "highlight": "Gratis: GPT-5-Codex a través de Factory AI.",
          "bullets": [
            "GPT-5-Codex model",
            "100 % gratis",
            "Factory AI platform"
          ],
          "note": "Requiere workaround (ver más abajo)."
        }
      },
      "quickStart": {
        "title": "Workshop Repo — empezá ahora",
        "description": "Repositorio listo con BMAD preinstalado, scripts de setup y MCPs configurados.",
        "bullets": [
          "BMAD pre-instalado y configurado",
          "Script de setup para Droid CLI (gratis)",
          "MCPs incluidos (Sequential Thinking, Playwright)",
          "Comandos BMAD listos para usar",
          "Workflows de ejemplo"
        ],
        "linkLabel": "github.com/baisharg/Workshop-Vibe-Coding",
        "note": "El script instala Droid CLI (gratis, GPT-5-Codex) y configura todos los comandos BMAD automáticamente.",
        "calloutLabel": "Quick start"
      },
      "learningTitle": "Repositorios y aprendizaje",
      "learning": {
        "bmadRepository": {
          "title": "BMAD Repository",
          "description": "Repositorio completo con prompts, documentación y ejemplos.",
          "bullets": [
            "Prompts de los 8 agentes",
            "Setup automatizado",
            "Documentación completa",
            "Ejemplos de proyectos"
          ],
          "linkLabel": "github.com/bmad-code-org/bmad-method"
        },
        "bmadMasterclass": {
          "title": "BMAD Method Masterclass",
          "description": "Tutorial en video que recorre el método de punta a punta.",
          "bullets": [
            "Setup paso a paso",
            "Uso de cada agente",
            "Workflow completo",
            "Ejemplos en vivo"
          ],
          "linkLabel": "youtu.be/LorEJPrALcg"
        }
      },
      "plansTitle": "Planes recomendados",
      "plans": {
        "zaiPlan": {
          "title": "Z.ai Coding Plan",
          "highlight": "Recomendado: opción económica para estudiantes y makers.",
          "bullets": [
            "Solo $3/mes",
            "Modelo GLM 4.6",
            "Performance cercana a Sonnet 4",
            "Ideal para estudiantes"
          ],
          "linkLabel": "z.ai/subscribe"
        },
        "claudeMax": {
          "title": "Claude Code + Max Plan",
          "highlight": "Para entusiastas: máxima calidad para agentic coding.",
          "bullets": [
            "Terminal Agent oficial de Anthropic",
            "Acceso a Sonnet 4.5",
            "Max Plan: $100/mes con límites altos",
            "Experiencia optimizada para agentes"
          ],
          "linkLabel": "claude.com/product/claude-code"
        },
        "githubStudent": {
          "title": "GitHub Student Pack",
          "highlight": "Si sos estudiante, conseguís Copilot Pro gratis.",
          "bullets": [
            "Copilot Pro incluido",
            "Acceso a Sonnet 4.5",
            "Mejor modelo del benchmark",
            "Sin costo para estudiantes"
          ],
          "linkLabel": "education.github.com/pack"
        }
      },
      "cliTitle": "Herramientas CLI / Terminal",
      "cliInstallLabel": "Instalación:",
      "cliSetupLabel": "Configuración BMAD:",
      "cli": {
        "openCode": {
          "title": "OpenCode",
          "description": "Programa de terminal open source. Te logueás con tu proveedor y OpenCode usa ese plan.",
          "bullets": [
            "Login con Anthropic, Copilot, Z.ai, etc.",
            "Corre en la terminal de cualquier IDE",
            "Compatible con MCP servers",
            "Multi-modelo y open source"
          ],
          "linkLabel": "opencode.ai",
          "steps": [
            "Instalá BMAD seleccionando la opción «Claude Code».",
            "Renombrá el directorio .claude/ a .opencode/.",
            "Pasá los archivos .md al nivel superior (no dentro de agents/ o tasks/)."
          ],
          "note": "Requiere workaround para mapear la carpeta de BMAD."
        },
        "droidCli": {
          "title": "Droid CLI",
          "description": "Cliente de Factory AI que expone GPT-5-Codex gratis, compatible con BMAD.",
          "bullets": [
            "Modelo GPT-5-Codex",
            "Completamente gratis",
            "Terminal program orientado a agentes"
          ],
          "linkLabel": "docs.factory.ai/cli",
          "steps": [
            "Instalá BMAD seleccionando la opción «Claude Code».",
            "Renombrá .claude/ a .factory/.",
            "Mové los archivos .md al nivel superior de .factory/."
          ],
          "note": "Workaround similar al de OpenCode para reutilizar los prompts."
        }
      },
      "setupTitle": "Instalación y setup",
      "setup": {
        "installBmad": {
          "title": "Instalación de BMAD",
          "description": "BMAD se instala por proyecto en el directorio raíz, dejando todo versionable.",
          "commandLabel": "En la raíz de tu proyecto:",
          "bullets": [
            "Crea la carpeta .bmad-core/ con agentes y templates.",
            "Instalación por proyecto (no global).",
            "Todo queda bajo control de versiones."
          ]
        },
        "recommendedMcps": {
          "title": "MCP Tools recomendadas",
          "description": "Herramientas que amplían las capacidades de los agentes.",
          "bullets": [
            "Playwright: browser automation para testing E2E.",
            "Sequential Thinking: razonamiento estructurado.",
            "Explorá más MCPs en el repositorio de Smithery."
          ],
          "linkLabel": "smithery.ai — repositorio de MCP tools",
          "note": "Configurá los MCPs en tu IDE y los agentes los usarán cuando los necesiten."
        }
      }
    }
  }
}
